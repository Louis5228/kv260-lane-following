{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7419ff",
   "metadata": {},
   "source": [
    "# Customized CNN inference\n",
    "This notebook will take you to inference a 18 class CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0b7e4",
   "metadata": {},
   "source": [
    "## Prepare the overlay\n",
    "We will download the overlay onto the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d528da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b89a5",
   "metadata": {},
   "source": [
    "## Import commom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b48295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8785a",
   "metadata": {},
   "source": [
    "## Load pretrained model (.xmodel)\n",
    "The `load_model()` method will automatically prepare the graph which is used by VART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0398a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"lane_following.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1f3df",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "We will prepare a few useful preprocessing functions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece93058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGR2RGB(image):\n",
    "    B, G, R = cv2.split(image)\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def normalize(image):\n",
    "    return np.asarray(image/255.0, dtype=np.float32)\n",
    "\n",
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result\n",
    "\n",
    "def preprocess_fn(image):\n",
    "    image = BGR2RGB(image)\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c1bf6",
   "metadata": {},
   "source": [
    "## Prepare inference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e7946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o -q dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8359de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test images: 852\n",
      "Dimension of each picture: 480x640\n",
      "Labels: 18\n",
      "['L_1', 'L_2', 'L_3', 'L_4', 'L_5', 'L_6', 'L_7', 'L_8', 'R_1', 'R_2', 'R_3', 'R_4', 'R_5', 'R_6', 'R_7', 'R_8', 'S_L', 'S_R']\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "image_path = []\n",
    "total_images = 0\n",
    "\n",
    "image_folder = 'dataset/test_data'\n",
    "dirs = os.listdir(image_folder)\n",
    "dirs.sort()\n",
    "for d in dirs:\n",
    "    labels.append(d)\n",
    "    tmp_path = []\n",
    "    dirs1 = os.listdir(image_folder + '/' + d)\n",
    "    dirs1.sort()\n",
    "    for d2 in dirs1:\n",
    "        tmp_path.append(image_folder + '/' + d + '/' + d2)\n",
    "    image_path.append(tmp_path)\n",
    "    total_images += len(tmp_path)\n",
    "\n",
    "print(\"Total number of test images: {}\".format(total_images))\n",
    "print(\"Dimension of each picture: {}x{}\".format(cv2.imread(image_path[0][0]).shape[0], \n",
    "                                                cv2.imread(image_path[0][0]).shape[1]))\n",
    "print(\"Labels: {}\\n{}\".format(len(labels), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2a86a",
   "metadata": {},
   "source": [
    "## Use VART\n",
    "Now we should be able to use *VART* to do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ac99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b3e26",
   "metadata": {},
   "source": [
    "We can define a few buffers to store input and output data. They will be reused during multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf82638",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41538a0",
   "metadata": {},
   "source": [
    "## Run DPU to make predictions\n",
    "We make predictions over the entire test dataset and calculate accuracy and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aed647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 852 images ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating {} images ...\".format(total_images))\n",
    "correct = 0\n",
    "\n",
    "start = time.time()\n",
    "for label in range(len(labels)):\n",
    "    for image_index in range(len(image_path[label])):\n",
    "        \n",
    "        test_data = cv2.imread(image_path[label][image_index])\n",
    "        input_data[0] = preprocess_fn(test_data)\n",
    "        \n",
    "        job_id = dpu.execute_async(input_data, output_data)\n",
    "        dpu.wait(job_id)\n",
    "        \n",
    "        probs = calculate_softmax(output_data[0])\n",
    "        predict = np.argmax(probs)\n",
    "        correct += (predict == label)\n",
    "\n",
    "stop = time.time()\n",
    "execution_time = stop - start\n",
    "print(\"Overall accuracy: {:.2f}%\".format((correct/total_images)*100))\n",
    "print(\"  Execution time: {:.4f}s\".format(execution_time))\n",
    "print(\"     Performance: {:.4f}FPS\".format(total_images/execution_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994b2e9",
   "metadata": {},
   "source": [
    "## Randomly select a picture to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ec959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOnce(labels, image_path):\n",
    "    \n",
    "    label = random.randint(0, len(labels)-1)\n",
    "    num_label_images = len(image_path[label])\n",
    "    image_index = random.randint(0, num_label_images-1)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    test_data = cv2.imread(image_path[label][image_index])\n",
    "    input_data[0] = preprocess_fn(test_data)\n",
    "    \n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    probs = calculate_softmax(output_data[0])\n",
    "    predict = np.argmax(probs)\n",
    "    \n",
    "    stop = time.time()\n",
    "    execution_time = stop - start\n",
    "    \n",
    "    print(\"Image label: {}\".format(labels[label]))\n",
    "    print(\"Predicted label: {}\".format(labels[predict]))\n",
    "    print(\"Execution time: {:.4f}s\".format(execution_time))\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(test_data, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runOnce(labels, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0880a51",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "We will need to remove references to *vart.Runner*. This will make sure we can run other notebooks without any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
